import httpx
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
import httpx
import os
from fastapi.responses import JSONResponse

router = APIRouter()

class GenerateRequest(BaseModel):
    model: str
    prompt: str | None = None  # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì±… ì´ë¦„ì´ë‚˜ í‚¤ì›Œë“œ
    mode: str  # 'novel', 'analyze', 'poem', 'book'
    stream: bool = False
    system: str | None = None

class GenerateResponse(BaseModel):
    response: str

# LLM ì„œë¹„ìŠ¤ URL (í™˜ê²½ë³€ìˆ˜ë¡œë„ ì„¤ì • ê°€ëŠ¥)
LLM_SERVICE_URL = os.getenv("LLM_SERVICE_URL", "http://localhost:11434/api/generate")
DEFAULT_MODEL = os.getenv("DEFAULT_MODEL", "gemma3:4b")

GOOGLE_BOOKS_API = "https://www.googleapis.com/books/v1/volumes"

@router.post("")
async def generate(req: GenerateRequest):
    """
    POST /api/generate
    body: {
      prompt: str,
      system?: str
    }
    """
    try:
        if req.mode == "book":
            if not req.prompt:
                raise HTTPException(status_code=400, detail="ì±… í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
            # Google Books API í˜¸ì¶œ
            async with httpx.AsyncClient() as client:
                params = {
                    "q": req.prompt,
                    "maxResults": 3,
                    "printType": "books",
                    "langRestrict": "ko"
                }
                resp = await client.get(GOOGLE_BOOKS_API, params=params)
                if resp.status_code != 200:
                    raise HTTPException(status_code=resp.status_code, detail="Google Books API ì˜¤ë¥˜")

                data = resp.json()
                books = data.get("items", [])
                if not books:
                    return JSONResponse(
                        content={"response": "ì¶”ì²œí•  ì±…ì´ ì—†ìŠµë‹ˆë‹¤."},
                        media_type="application/json; charset=utf-8"
                    )

                results = []
                for book in books:
                    info = book["volumeInfo"]
                    title = info.get("title", "ì œëª© ì—†ìŒ")
                    authors = ", ".join(info.get("authors", []))
                    desc = info.get("description", "ì„¤ëª…ì´ ì—†ìŠµë‹ˆë‹¤.")
                    results.append(f"ğŸ“š ì œëª©: {title}\nğŸ‘¤ ì €ì: {authors}\nğŸ“ ì†Œê°œ: {desc[:100]}...\n")

                return JSONResponse(
                    content={"response": "\n\n".join(results)},
                    media_type="application/json; charset=utf-8"
                )
        
        # LLM ì„œë¹„ìŠ¤ í˜¸ì¶œ
        payload = {
            "model": req.model or DEFAULT_MODEL,
            "prompt": req.prompt,
            "stream": req.stream,
        }
        if req.system:
            payload["system"] = req.system

        async with httpx.AsyncClient(timeout=60.0) as client:
            resp = await client.post(LLM_SERVICE_URL, json=payload)
            resp.encoding = 'utf-8'
            data = resp.json()

        result = data.get("response")
        if not result:
            return JSONResponse(
                content={"response": "ì‘ë‹µì„ ì´í•´í•˜ì§€ ëª»í–ˆì–´ìš”."},
                media_type="application/json; charset=utf-8"
            )
        return JSONResponse(
            content={"response": result},
            media_type="application/json; charset=utf-8"
        )

    except httpx.HTTPError as e:
        # LLM ì„œë¹„ìŠ¤ í˜¸ì¶œì— ì‹¤íŒ¨í–ˆì„ ë•Œ
        raise HTTPException(status_code=502, detail=f"AI ì—°ê²° ì‹¤íŒ¨: {str(e)}")
    except Exception as e:
        # ê¸°íƒ€ ì˜ˆì™¸ ìƒí™©
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}")
