import httpx
from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
import os
from fastapi.responses import JSONResponse, Response
from typing import Optional

# ìƒìˆ˜ ì •ì˜
LLM_SERVICE_URL = os.getenv("LLM_SERVICE_URL", "http://localhost:11434/api/generate")
DEFAULT_MODEL = os.getenv("DEFAULT_MODEL", "gemma3:4b")
GOOGLE_BOOKS_API = "https://www.googleapis.com/books/v1/volumes"
MAX_BOOK_RESULTS = 3
BOOK_DESC_LENGTH = 100

router = APIRouter()

class GenerateRequest(BaseModel):
    model: str
    prompt: Optional[str] = None
    mode: str  # 'novel', 'analyze', 'poem', 'book'
    stream: bool = False
    system: Optional[str] = None

class GenerateResponse(BaseModel):
    response: str

async def fetch_google_books(prompt: str) -> list:
    """Google Books APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì±… ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    async with httpx.AsyncClient() as client:
        params = {
            "q": prompt,
            "maxResults": MAX_BOOK_RESULTS,
            "printType": "books",
            "langRestrict": "ko"
        }
        resp = await client.get(GOOGLE_BOOKS_API, params=params)
        if resp.status_code != 200:
            raise HTTPException(status_code=resp.status_code, detail="Google Books API ì˜¤ë¥˜")
        return resp.json().get("items", [])

def format_book_info(book: dict) -> str:
    """ì±… ì •ë³´ë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
    info = book["volumeInfo"]
    title = info.get("title", "ì œëª© ì—†ìŒ")
    authors = ", ".join(info.get("authors", []))
    desc = info.get("description", "ì„¤ëª…ì´ ì—†ìŠµë‹ˆë‹¤.")
    return f"ğŸ“š ì œëª©: {title}\nğŸ‘¤ ì €ì: {authors}\nğŸ“ ì†Œê°œ: {desc[:BOOK_DESC_LENGTH]}...\n"

async def call_llm_service(payload: dict) -> str:
    """LLM ì„œë¹„ìŠ¤ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    async with httpx.AsyncClient(timeout=60.0) as client:
        resp = await client.post(LLM_SERVICE_URL, json=payload)
        try:
            data = resp.json()
            return data.get("response", resp.text)
        except Exception:
            return resp.text

@router.post("")
async def generate(req: GenerateRequest):
    """
    POST /api/generate
    body: {
      prompt: str,
      system?: str
    }
    """
    try:
        if req.mode == "book":
            if not req.prompt:
                raise HTTPException(status_code=400, detail="ì±… í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
            books = await fetch_google_books(req.prompt)
            if not books:
                return JSONResponse(
                    content={"response": "ì¶”ì²œí•  ì±…ì´ ì—†ìŠµë‹ˆë‹¤."},
                    media_type="application/json"
                )

            results = [format_book_info(book) for book in books]
            return JSONResponse(
                content={"response": "\n\n".join(results)},
                media_type="application/json"
            )
        
        # LLM ì„œë¹„ìŠ¤ í˜¸ì¶œ
        payload = {
            "model": req.model or DEFAULT_MODEL,
            "prompt": req.prompt,
            "stream": req.stream,
        }
        if req.system:
            payload["system"] = req.system

        result = await call_llm_service(payload)
        if not result:
            return JSONResponse(
                content={"response": "ì‘ë‹µì„ ì´í•´í•˜ì§€ ëª»í–ˆì–´ìš”."},
                media_type="application/json"
            )
        
        return JSONResponse(
            content={"response": result},
            media_type="application/json"
        )

    except httpx.HTTPError as e:
        # LLM ì„œë¹„ìŠ¤ í˜¸ì¶œì— ì‹¤íŒ¨í–ˆì„ ë•Œ
        raise HTTPException(status_code=502, detail=f"AI ì—°ê²° ì‹¤íŒ¨: {str(e)}")
    except Exception as e:
        # ê¸°íƒ€ ì˜ˆì™¸ ìƒí™©
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}")
